{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Pagination through user timeline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import tweepy\n",
      "from tweepy import StreamListener\n",
      "import json, time, sys\n",
      "\n",
      "consumer_key        = \"xLNSlDfsYDWoVDVlnUewog\"\n",
      "consumer_secret     = \"cysEIjDiZ29J81XbMpzXndE0s7cAL5lX7XygY4G80Qc\"\n",
      "access_token        = \"29499583-TN805p7dPVvBnaBhU5ldegeQTx16JqYMaFM8AkzSo\"\n",
      "access_token_secret = \"dd4cSOXoruGfoykzlx6gHcSTIEQDuQkTsW4qobFyds\"\n",
      "\n",
      "# OAuth process, using the keys and tokens\n",
      "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
      "auth.set_access_token(access_token, access_token_secret)\n",
      "api = tweepy.API(auth)\n",
      "\n",
      "for page in tweepy.Cursor(api.user_timeline).pages(3):\n",
      "        for item in page:\n",
      "                print item.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "https://github.com/nirg/tweepy/blob/master/examples/paginated_search.py\n",
      "http://www.nirg.net/blog/2013/04/using-tweepy/"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import tweepy\n",
      "from tweepy import StreamListener\n",
      "import json, time, sys\n",
      "\n",
      "consumer_key        = \"xLNSlDfsYDWoVDVlnUewog\"\n",
      "consumer_secret     = \"cysEIjDiZ29J81XbMpzXndE0s7cAL5lX7XygY4G80Qc\"\n",
      "access_token        = \"29499583-TN805p7dPVvBnaBhU5ldegeQTx16JqYMaFM8AkzSo\"\n",
      "access_token_secret = \"dd4cSOXoruGfoykzlx6gHcSTIEQDuQkTsW4qobFyds\"\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
      "    auth.set_access_token(access_token, access_token_secret)\n",
      "    \n",
      "    api = tweepy.API([auth], # support for multiple authentication handlers\n",
      "                     retry_count=3, retry_delay=5, retry_errors=set([401, 404, 500, 503]), # retry 3 times with 5 seconds delay when getting these error codes. For more details see https://dev.twitter.com/docs/error-codes-responses\n",
      "                     monitor_rate_limit=True, wait_on_rate_limit=True # monitor remaining calls and block until replenished\n",
      "                    )\n",
      "    # recommended best practice is no more than 10 OR's in a query\n",
      "    #1 query = 'KirkDBorne OR jameskobielus OR timoelliott OR BernardMarr OR kdnuggets OR mgualtieri OR Doug_Laney OR Natasha_D_G OR DHenschen OR jamet123'\n",
      "    #2 query = 'burkepowers OR dawnmevans OR ThorOlavsrud OR philsimon OR Brian_Eastwood OR rwang0 OR NadhanAtHP OR nstevenlucas OR mjcavaretta OR kncukier'\n",
      "    #3 query = 'Viktor_MS OR Joab_Jackson OR sharon000 OR mchui OR merv OR mjasay OR johnkwaters OR SethGrimes OR practicingEA OR bobehayes'\n",
      "    #4 query = 'data_nerd OR SteveLohr OR jbertolucci OR billfranksga OR vincos OR spoonen OR PatrickMeier OR dhinchcliffe OR hkisker OR bakercom1' \n",
      "    #5 query = 'Digitaltonto OR andrewbrust OR jilldyche OR YvesMulkers OR marcusborba OR erikbryn OR davidedelman OR dannyjpalmer OR ocdqblog' \n",
      "    query = 'spss'\n",
      "    page_count = 0\n",
      "    tweetCount = 1\n",
      "    allTweets = []\n",
      "    for tweets in tweepy.Cursor(api.search, q=query, count=100, lang=\"en\", result_type=\"recent\", include_entities=True).pages():\n",
      "        page_count += 1\n",
      "        for i in range(len(tweets)):\n",
      "            \"\"\"\n",
      "            print tweetCount\n",
      "            print tweets[i].user.name\n",
      "            print tweets[i].created_at\n",
      "            print tweets[i].text.encode('utf-8')\n",
      "            print \"\\n\"\n",
      "            \"\"\"\n",
      "            tweetCount += 1\n",
      "            allTweets.append(tweets[i])\n",
      "        # stop after retrieving 200 pages\n",
      "        if page_count >= 50:#200\n",
      "            break\n",
      "            \n",
      "    from openpyxl import Workbook\n",
      "    wb = Workbook()\n",
      "    ws = wb.get_active_sheet()\n",
      "    \n",
      "    dest_filename = 'C:/Projects/ipython/data/searchTweets17.xlsx'#r'test_book.xlsx'\n",
      "    \n",
      "    ws = wb.worksheets[0]\n",
      "    \n",
      "    ws.title = \"Twitter\"\n",
      "    \n",
      "    # create header\n",
      "    ws.cell('A1').value = 'TweetID'\n",
      "    ws.cell('B1').value = 'TweetDateTime'\n",
      "    ws.cell('C1').value = 'Author_ID'\n",
      "    ws.cell('D1').value = 'TweetText'\n",
      "    ws.cell('E1').value = 'RetweetCount'\n",
      "    ws.cell('F1').value = 'FavoriteCount'\n",
      "    ws.cell('G1').value = 'UserMentions'\n",
      "    ws.cell('H1').value = 'Hashtags'\n",
      "    ws.cell('I1').value = 'URLs'\n",
      "    ws.cell('J1').value = 'AuthorName'\n",
      "    ws.cell('K1').value = 'FollowersCount'\n",
      "    ws.cell('L1').value = 'FriendsCount'\n",
      "    ws.cell('M1').value = 'StatusesCount'\n",
      "    ws.cell('N1').value = 'UserLocation'\n",
      "    ws.cell('O1').value = 'Description'\n",
      "    ws.cell('P1').value = 'TwitterHandle'\n",
      "    \n",
      "    i = 2\n",
      "    for tweet in allTweets:\n",
      "        if tweet.id: #'TweetID'\n",
      "            ws.cell('%s%s'%('A', i)).value = tweet.id\n",
      "        else:\n",
      "            ws.cell('%s%s'%('A', i)).value = \"\" \n",
      "        \n",
      "        if tweet.created_at: #'TweetDateTime'\n",
      "            ws.cell('%s%s'%('B', i)).value = tweet.created_at \n",
      "        else:\n",
      "            ws.cell('%s%s'%('B', i)).value = \"\"        \n",
      "        \n",
      "        if tweet.user.id: #'Author_ID'\n",
      "            ws.cell('%s%s'%('C', i)).value = tweet.user.id \n",
      "        else:\n",
      "            ws.cell('%s%s'%('C', i)).value = \"\"\n",
      "            \n",
      "        if tweet.text: #'TweetText'\n",
      "            ws.cell('%s%s'%('D', i)).value = tweet.text.encode('utf-8') \n",
      "        else:\n",
      "            ws.cell('%s%s'%('D', i)).value = \"\"\n",
      "            \n",
      "        if tweet.retweet_count: #'RetweetCount'\n",
      "            ws.cell('%s%s'%('E', i)).value = tweet.retweet_count \n",
      "        else:\n",
      "            ws.cell('%s%s'%('E', i)).value = \"\"\n",
      "            \n",
      "        if tweet.favorite_count: #'FavoriteCount'\n",
      "            ws.cell('%s%s'%('F', i)).value = tweet.favorite_count \n",
      "        else:\n",
      "            ws.cell('%s%s'%('F', i)).value = \"\"\n",
      "           \n",
      "        if tweet.entities: #'UserMentions'\n",
      "            mentions = \"\"\n",
      "            if 'user_mentions' in tweet.entities:                \n",
      "                for j in range(0,len(tweet.entities['user_mentions'])):\n",
      "                    mentions = mentions + tweet.entities['user_mentions'][j]['screen_name'].encode('utf-8') + \"|\"\n",
      "            ws.cell('%s%s'%('G', i)).value = mentions\n",
      "        else:\n",
      "            ws.cell('%s%s'%('G', i)).value = \"\"\n",
      "             \n",
      "        if tweet.entities: #'Hashtags'\n",
      "            hashtags = \"\"\n",
      "            if 'hashtags' in tweet.entities: \n",
      "                for j in range(0,len(tweet.entities['hashtags'])):\n",
      "                    hashtags = hashtags + tweet.entities['hashtags'][j]['text'].encode('utf-8') + \"|\"\n",
      "            ws.cell('%s%s'%('H', i)).value = hashtags\n",
      "        else:\n",
      "            ws.cell('%s%s'%('H', i)).value = \"\"\n",
      "            \n",
      "        if tweet.entities: #'URLs'\n",
      "            urls = \"\"\n",
      "            if 'urls' in tweet.entities:                \n",
      "                for j in range(0,len(tweet.entities['urls'])):\n",
      "                    urls = urls + tweet.entities['urls'][j]['expanded_url'].encode('utf-8') + \"|\"\n",
      "            ws.cell('%s%s'%('I', i)).value = urls \n",
      "        else:\n",
      "            ws.cell('%s%s'%('I', i)).value = \"\"\n",
      "            \n",
      "        if tweet.user.name: #'AuthorName'\n",
      "            ws.cell('%s%s'%('J', i)).value = tweet.user.name.encode('utf-8')\n",
      "        else:\n",
      "            ws.cell('%s%s'%('J', i)).value = \"\"\n",
      "            \n",
      "        if tweet.user.followers_count: #'FollowersCount'\n",
      "            ws.cell('%s%s'%('K', i)).value = tweet.user.followers_count \n",
      "        else:\n",
      "            ws.cell('%s%s'%('K', i)).value = \"\"\n",
      "            \n",
      "        if tweet.user.friends_count: #'FriendsCount'\n",
      "            ws.cell('%s%s'%('L', i)).value = tweet.user.friends_count \n",
      "        else:\n",
      "            ws.cell('%s%s'%('L', i)).value = \"\"\n",
      "            \n",
      "        if tweet.user.statuses_count: #'StatusesCount'\n",
      "            ws.cell('%s%s'%('M', i)).value = tweet.user.statuses_count\n",
      "        else:\n",
      "            ws.cell('%s%s'%('M', i)).value = \"\"\n",
      "            \n",
      "        if tweet.user.location: #'UserLocation'\n",
      "            ws.cell('%s%s'%('N', i)).value = tweet.user.location.encode('utf-8')\n",
      "        else:\n",
      "            ws.cell('%s%s'%('N', i)).value = \"\"\n",
      "            \n",
      "        if tweet.user.description: #'Description'\n",
      "            ws.cell('%s%s'%('O', i)).value = tweet.user.description.encode('utf-8') \n",
      "        else:\n",
      "            ws.cell('%s%s'%('O', i)).value = \"\"\n",
      "        \n",
      "        if tweet.user.screen_name: #'AuthorHandle'\n",
      "            ws.cell('%s%s'%('P', i)).value = tweet.user.screen_name.encode('utf-8')\n",
      "        else:\n",
      "            ws.cell('%s%s'%('P', i)).value = \"\"\n",
      "            \n",
      "        i += 1\n",
      "       \n",
      "    wb.save(filename = dest_filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Version 2:\n",
      "\n",
      "This version will take a long list of terms and search for them with the assumption that they should all use the OR operand."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "termList = []\n",
      "termList.append('KirkDBorne')\n",
      "termList.append('jameskobielus')\n",
      "termList.append('timoelliott')\n",
      "termList.append('BernardMarr')\n",
      "termList.append('kdnuggets')\n",
      "termList.append('mgualtieri')\n",
      "termList.append('Doug_Laney')\n",
      "termList.append('Natasha_D_G')\n",
      "termList.append('DHenschen')\n",
      "termList.append('jamet123')\n",
      "termList.append('burkepowers')\n",
      "termList.append('dawnmevans')\n",
      "termList.append('ThorOlavsrud')\n",
      "termList.append('philsimon')\n",
      "termList.append('Brian_Eastwood')\n",
      "termList.append('rwang0')\n",
      "termList.append('NadhanAtHP')\n",
      "termList.append('nstevenlucas')\n",
      "termList.append('mjcavaretta')\n",
      "termList.append('kncukier')\n",
      "termList.append('Viktor_MS')\n",
      "termList.append('Joab_Jackson')\n",
      "termList.append('sharon000')\n",
      "termList.append('mchui')\n",
      "termList.append('@merv ')\n",
      "termList.append('mjasay')\n",
      "termList.append('johnkwaters')\n",
      "termList.append('SethGrimes')\n",
      "termList.append('practicingEA')\n",
      "termList.append('bobehayes')\n",
      "termList.append('data_nerd')\n",
      "termList.append('SteveLohr')\n",
      "termList.append('jbertolucci')\n",
      "termList.append('billfranksga')\n",
      "termList.append('vincos')\n",
      "termList.append('spoonen')\n",
      "termList.append('PatrickMeier')\n",
      "termList.append('dhinchcliffe')\n",
      "termList.append('hkisker')\n",
      "termList.append('bakercom1')\n",
      "termList.append('Digitaltonto')\n",
      "termList.append('andrewbrust')\n",
      "termList.append('jilldyche')\n",
      "termList.append('YvesMulkers')\n",
      "termList.append('marcusborba')\n",
      "termList.append('erikbryn')\n",
      "termList.append('davidedelman')\n",
      "termList.append('dannyjpalmer')\n",
      "termList.append('ocdqblog')\n",
      "termList.append('jhurwitz')\n",
      "termList.append('BigDataGal')\n",
      "termList.append('jeffreyfkelly')\n",
      "termList.append('JohndeVoogd')\n",
      "termList.append('Claudia_Imhoff')\n",
      "termList.append('MDMGeek')\n",
      "termList.append('BigData_paulz')\n",
      "termList.append('fredtrotter')\n",
      "termList.append('revodavid')\n",
      "termList.append('JWVance')\n",
      "termList.append('andrejverity')\n",
      "termList.append('lisaarthur')\n",
      "termList.append('graemeknows')\n",
      "termList.append('BeverlyMacy')\n",
      "termList.append('lauriemccabe')\n",
      "termList.append('VanRijmenam')\n",
      "termList.append('lisagualtieri')\n",
      "termList.append('Joseph_Marks_')\n",
      "termList.append('shawnrog')\n",
      "termList.append('ellisbooker')\n",
      "termList.append('rgkirkpatrick')\n",
      "termList.append('ValaAfshar')\n",
      "termList.append('jenstirrup')\n",
      "termList.append('marksmithvr')\n",
      "termList.append('setlinger')\n",
      "termList.append('mraad')\n",
      "termList.append('vijayasankarv')\n",
      "termList.append('John4man')\n",
      "termList.append('NeilRaden')\n",
      "termList.append('Dana_Gardner')\n",
      "termList.append('maslett')\n",
      "termList.append('dvellante')\n",
      "termList.append('tcrawford')\n",
      "termList.append('nyike')\n",
      "termList.append('mikeolson')\n",
      "termList.append('Colinstrong')\n",
      "termList.append('DTurnerBlogs')\n",
      "termList.append('jburnmurdoch')\n",
      "termList.append('TheGrok')\n",
      "termList.append('TheSocialPitt')\n",
      "termList.append('eric_kavanagh')\n",
      "termList.append('AliRebaie')\n",
      "termList.append('louleporace')\n",
      "termList.append('ITredux')\n",
      "termList.append('jasonaverbook')\n",
      "termList.append('BarryDevlin')\n",
      "termList.append('shaunconnolly')\n",
      "termList.append('RetailProphet')\n",
      "termList.append('TonyCosentinoVR')\n",
      "termList.append('lucadebiase')\n",
      "termList.append('aregenberg')\n",
      "termList.append('LoraineLawson')\n",
      "termList.append('prussom')\n",
      "termList.append('Josh_Bersin')\n",
      "termList.append('fhalper')\n",
      "termList.append('BillRuh_GE')\n",
      "termList.append('imbigdata')\n",
      "termList.append('bobevansIT')\n",
      "termList.append('lucatbarone')\n",
      "termList.append('spangledrongo')\n",
      "termList.append('InfoMgmtExec')\n",
      "termList.append('sinanaral')\n",
      "termList.append('tamaradull')\n",
      "termList.append('tweetsinha')\n",
      "termList.append('EricDBrown')\n",
      "termList.append('jfoley09')\n",
      "termList.append('acroll')\n",
      "termList.append('ColinJWhite')\n",
      "termList.append('smoneill')\n",
      "termList.append('juliebhunt')\n",
      "termList.append('nicfish')\n",
      "termList.append('gkm1')\n",
      "termList.append('williammcknight')\n",
      "termList.append('jaimefitzgerald')\n",
      "termList.append('craigmullins')\n",
      "termList.append('brunoaziza')\n",
      "termList.append('PaulDunay')\n",
      "termList.append('BigDataSpeaker')\n",
      "termList.append('WillmottPaul')\n",
      "termList.append('johnlmyers44')\n",
      "termList.append('tunvall')\n",
      "termList.append('rcalo')\n",
      "termList.append('gleonhard')\n",
      "termList.append('nancykoppdw')\n",
      "termList.append('DavidLinthicum')\n",
      "termList.append('jbdezard')\n",
      "termList.append('bigdata')\n",
      "termList.append('vmugonline')\n",
      "termList.append('estebanmoro')\n",
      "termList.append('FrankBuytendijk')\n",
      "termList.append('BITechWatch')\n",
      "termList.append('davidfcarr')\n",
      "termList.append('dr_morton')\n",
      "termList.append('sandy_carter')\n",
      "termList.append('DrBonnie360')\n",
      "termList.append('simonlporter')\n",
      "termList.append('Darryl_McDonald')\n",
      "termList.append('jg21')\n",
      "termList.append('Enderle')\n",
      "termList.append('MandiBPro')\n",
      "termList.append('pacoid')\n",
      "termList.append('HugoSarrazin')\n",
      "termList.append('FindChrisTaylor')\n",
      "termList.append('HealthcareWen')\n",
      "termList.append('adsuara')\n",
      "termList.append('christianve')\n",
      "termList.append('hlsdk')\n",
      "termList.append('SameerPatel')\n",
      "termList.append('BradfordBrown')\n",
      "termList.append('JamesMaguire')\n",
      "termList.append('marcteerlink')\n",
      "termList.append('Hypatia_LeslieA')\n",
      "termList.append('bevelson')\n",
      "termList.append('ABridgwater')\n",
      "termList.append('bkardon')\n",
      "termList.append('PepeCerezo')\n",
      "termList.append('tpowlas')\n",
      "termList.append('petervan')\n",
      "termList.append('MarkBonchek')\n",
      "termList.append('slfisher')\n",
      "termList.append('WyattKash')\n",
      "termList.append('David_MSullivan')\n",
      "termList.append('rjwissin')\n",
      "termList.append('datagenius')\n",
      "termList.append('ronbodkin')\n",
      "termList.append('Guille_Mas')\n",
      "termList.append('digitalarun')\n",
      "termList.append('sorayapa')\n",
      "termList.append('DavidAmerland')\n",
      "termList.append('etamb')\n",
      "termList.append('applebyj')\n",
      "termList.append('ajbowles')\n",
      "termList.append('rsallam')\n",
      "termList.append('mphnyc')\n",
      "termList.append('idin77')\n",
      "termList.append('robinbloor')\n",
      "termList.append('tinagroves')\n",
      "termList.append('kimdossey')\n",
      "termList.append('BobViolino')\n",
      "termList.append('richardwinter')\n",
      "termList.append('jahendler')\n",
      "termList.append('VishalTx')\n",
      "termList.append('Marsee')\n",
      "termList.append('Bilafer')\n",
      "termList.append('StacyLeidwinger')\n",
      "termList.append('mgershoff')\n",
      "termList.append('TonyBaer')\n",
      "termList.append('Charly_BG')\n",
      "termList.append('spss')\n",
      "termList.append('bigdata')\n",
      "termList.append('socbiz')\n",
      "termList.append('datamining')\n",
      "termList.append('analytics')\n",
      "\n",
      "  \n",
      "import tweepy\n",
      "from tweepy import StreamListener\n",
      "import json, time, sys\n",
      "\n",
      "consumer_key        = \"xLNSlDfsYDWoVDVlnUewog\"\n",
      "consumer_secret     = \"cysEIjDiZ29J81XbMpzXndE0s7cAL5lX7XygY4G80Qc\"\n",
      "access_token        = \"29499583-TN805p7dPVvBnaBhU5ldegeQTx16JqYMaFM8AkzSo\"\n",
      "access_token_secret = \"dd4cSOXoruGfoykzlx6gHcSTIEQDuQkTsW4qobFyds\"\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
      "    auth.set_access_token(access_token, access_token_secret)\n",
      "    \n",
      "    api = tweepy.API([auth], # support for multiple authentication handlers\n",
      "                     retry_count=3, retry_delay=5, retry_errors=set([401, 404, 500, 503]), # retry 3 times with 5 seconds delay when getting these error codes. For more details see https://dev.twitter.com/docs/error-codes-responses\n",
      "                     monitor_rate_limit=True, wait_on_rate_limit=True # monitor remaining calls and block until replenished\n",
      "                    )\n",
      "    # recommended best practice is no more than 10 OR's in a query\n",
      "    for i in range(0,len(termList),10):\n",
      "        query = \"\"\n",
      "        for j in range(0,10):\n",
      "            if i+j <= len(termList)-1:\n",
      "                if j < 9 and termList[i+j] <> termList[len(termList)-1]:\n",
      "                    query = query + \"\\'\" + termList[i+j] + \"\\' OR \"\n",
      "                else:\n",
      "                    query = query + \"\\'\" + termList[i+j] + \"\\'\"\n",
      "            else:\n",
      "                break\n",
      "        print query + \"\\n\\n\"\n",
      "        page_count = 0\n",
      "        tweetCount = 1\n",
      "        allTweets = []\n",
      "        for tweets in tweepy.Cursor(api.search, q=query, count=100, lang=\"en\", result_type=\"recent\", include_entities=True).pages():\n",
      "            page_count += 1\n",
      "            for i in range(len(tweets)):\n",
      "                \"\"\"\n",
      "                print tweetCount\n",
      "                print tweets[i].user.name\n",
      "                print tweets[i].created_at\n",
      "                print tweets[i].text.encode('utf-8')\n",
      "                print \"\\n\"\n",
      "                \"\"\"\n",
      "                tweetCount += 1\n",
      "                allTweets.append(tweets[i])\n",
      "            # stop after retrieving 200 pages\n",
      "            if page_count >= 50:#200\n",
      "                break\n",
      "                \n",
      "        from openpyxl import Workbook\n",
      "        wb = Workbook()\n",
      "        ws = wb.get_active_sheet()\n",
      "        \n",
      "        dest_filename = 'C:/Projects/ipython/data/searchTweets' + time.strftime('%Y%m%d-%H%M%S') + '.xlsx'#r'test_book.xlsx'\n",
      "        \n",
      "        ws = wb.worksheets[0]\n",
      "        \n",
      "        ws.title = \"Twitter\"\n",
      "        \n",
      "        # create header\n",
      "        ws.cell('A1').value = 'TweetID'\n",
      "        ws.cell('B1').value = 'TweetDateTime'\n",
      "        ws.cell('C1').value = 'Author_ID'\n",
      "        ws.cell('D1').value = 'TweetText'\n",
      "        ws.cell('E1').value = 'RetweetCount'\n",
      "        ws.cell('F1').value = 'FavoriteCount'\n",
      "        ws.cell('G1').value = 'UserMentions'\n",
      "        ws.cell('H1').value = 'Hashtags'\n",
      "        ws.cell('I1').value = 'URLs'\n",
      "        ws.cell('J1').value = 'AuthorName'\n",
      "        ws.cell('K1').value = 'FollowersCount'\n",
      "        ws.cell('L1').value = 'FriendsCount'\n",
      "        ws.cell('M1').value = 'StatusesCount'\n",
      "        ws.cell('N1').value = 'UserLocation'\n",
      "        ws.cell('O1').value = 'Description'\n",
      "        ws.cell('P1').value = 'TwitterHandle'\n",
      "        \n",
      "        i = 2\n",
      "        for tweet in allTweets:\n",
      "            if tweet.id: #'TweetID'\n",
      "                ws.cell('%s%s'%('A', i)).value = tweet.id\n",
      "            else:\n",
      "                ws.cell('%s%s'%('A', i)).value = \"\" \n",
      "            \n",
      "            if tweet.created_at: #'TweetDateTime'\n",
      "                ws.cell('%s%s'%('B', i)).value = tweet.created_at \n",
      "            else:\n",
      "                ws.cell('%s%s'%('B', i)).value = \"\"        \n",
      "            \n",
      "            if tweet.user.id: #'Author_ID'\n",
      "                ws.cell('%s%s'%('C', i)).value = tweet.user.id \n",
      "            else:\n",
      "                ws.cell('%s%s'%('C', i)).value = \"\"\n",
      "                \n",
      "            if tweet.text: #'TweetText'\n",
      "                ws.cell('%s%s'%('D', i)).value = tweet.text.encode('utf-8') \n",
      "            else:\n",
      "                ws.cell('%s%s'%('D', i)).value = \"\"\n",
      "                \n",
      "            if tweet.retweet_count: #'RetweetCount'\n",
      "                ws.cell('%s%s'%('E', i)).value = tweet.retweet_count \n",
      "            else:\n",
      "                ws.cell('%s%s'%('E', i)).value = \"\"\n",
      "                \n",
      "            if tweet.favorite_count: #'FavoriteCount'\n",
      "                ws.cell('%s%s'%('F', i)).value = tweet.favorite_count \n",
      "            else:\n",
      "                ws.cell('%s%s'%('F', i)).value = \"\"\n",
      "               \n",
      "            if tweet.entities: #'UserMentions'\n",
      "                mentions = \"\"\n",
      "                if 'user_mentions' in tweet.entities:                \n",
      "                    for j in range(0,len(tweet.entities['user_mentions'])):\n",
      "                        mentions = mentions + tweet.entities['user_mentions'][j]['screen_name'].encode('utf-8') + \"|\"\n",
      "                ws.cell('%s%s'%('G', i)).value = mentions\n",
      "            else:\n",
      "                ws.cell('%s%s'%('G', i)).value = \"\"\n",
      "                 \n",
      "            if tweet.entities: #'Hashtags'\n",
      "                hashtags = \"\"\n",
      "                if 'hashtags' in tweet.entities: \n",
      "                    for j in range(0,len(tweet.entities['hashtags'])):\n",
      "                        hashtags = hashtags + tweet.entities['hashtags'][j]['text'].encode('utf-8') + \"|\"\n",
      "                ws.cell('%s%s'%('H', i)).value = hashtags\n",
      "            else:\n",
      "                ws.cell('%s%s'%('H', i)).value = \"\"\n",
      "                \n",
      "            if tweet.entities: #'URLs'\n",
      "                urls = \"\"\n",
      "                if 'urls' in tweet.entities:                \n",
      "                    for j in range(0,len(tweet.entities['urls'])):\n",
      "                        urls = urls + tweet.entities['urls'][j]['expanded_url'].encode('utf-8') + \"|\"\n",
      "                ws.cell('%s%s'%('I', i)).value = urls \n",
      "            else:\n",
      "                ws.cell('%s%s'%('I', i)).value = \"\"\n",
      "                \n",
      "            if tweet.user.name: #'AuthorName'\n",
      "                ws.cell('%s%s'%('J', i)).value = tweet.user.name.encode('utf-8')\n",
      "            else:\n",
      "                ws.cell('%s%s'%('J', i)).value = \"\"\n",
      "                \n",
      "            if tweet.user.followers_count: #'FollowersCount'\n",
      "                ws.cell('%s%s'%('K', i)).value = tweet.user.followers_count \n",
      "            else:\n",
      "                ws.cell('%s%s'%('K', i)).value = \"\"\n",
      "                \n",
      "            if tweet.user.friends_count: #'FriendsCount'\n",
      "                ws.cell('%s%s'%('L', i)).value = tweet.user.friends_count \n",
      "            else:\n",
      "                ws.cell('%s%s'%('L', i)).value = \"\"\n",
      "                \n",
      "            if tweet.user.statuses_count: #'StatusesCount'\n",
      "                ws.cell('%s%s'%('M', i)).value = tweet.user.statuses_count\n",
      "            else:\n",
      "                ws.cell('%s%s'%('M', i)).value = \"\"\n",
      "                \n",
      "            if tweet.user.location: #'UserLocation'\n",
      "                ws.cell('%s%s'%('N', i)).value = tweet.user.location.encode('utf-8')\n",
      "            else:\n",
      "                ws.cell('%s%s'%('N', i)).value = \"\"\n",
      "                \n",
      "            if tweet.user.description: #'Description'\n",
      "                ws.cell('%s%s'%('O', i)).value = tweet.user.description.encode('utf-8') \n",
      "            else:\n",
      "                ws.cell('%s%s'%('O', i)).value = \"\"\n",
      "            \n",
      "            if tweet.user.screen_name: #'AuthorHandle'\n",
      "                ws.cell('%s%s'%('P', i)).value = tweet.user.screen_name.encode('utf-8')\n",
      "            else:\n",
      "                ws.cell('%s%s'%('P', i)).value = \"\"\n",
      "                \n",
      "            i += 1\n",
      "           \n",
      "        wb.save(filename = dest_filename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "'KirkDBorne' OR 'jameskobielus' OR 'timoelliott' OR 'BernardMarr' OR 'kdnuggets' OR 'mgualtieri' OR 'Doug_Laney' OR 'Natasha_D_G' OR 'DHenschen' OR 'jamet123'\n",
        "\n",
        "\n",
        "'burkepowers' OR 'dawnmevans' OR 'ThorOlavsrud' OR 'philsimon' OR 'Brian_Eastwood' OR 'rwang0' OR 'NadhanAtHP' OR 'nstevenlucas' OR 'mjcavaretta' OR 'kncukier'\n",
        "\n",
        "\n",
        "'Viktor_MS' OR 'Joab_Jackson' OR 'sharon000' OR 'mchui' OR '@merv ' OR 'mjasay' OR 'johnkwaters' OR 'SethGrimes' OR 'practicingEA' OR 'bobehayes'\n",
        "\n",
        "\n",
        "'data_nerd' OR 'SteveLohr' OR 'jbertolucci' OR 'billfranksga' OR 'vincos' OR 'spoonen' OR 'PatrickMeier' OR 'dhinchcliffe' OR 'hkisker' OR 'bakercom1'\n",
        "\n",
        "\n",
        "'Digitaltonto' OR 'andrewbrust' OR 'jilldyche' OR 'YvesMulkers' OR 'marcusborba' OR 'erikbryn' OR 'davidedelman' OR 'dannyjpalmer' OR 'ocdqblog' OR 'jhurwitz'\n",
        "\n",
        "\n",
        "'BigDataGal' OR 'jeffreyfkelly' OR 'JohndeVoogd' OR 'Claudia_Imhoff' OR 'MDMGeek' OR 'BigData_paulz' OR 'fredtrotter' OR 'revodavid' OR 'JWVance' OR 'andrejverity'\n",
        "\n",
        "\n",
        "'lisaarthur' OR 'graemeknows' OR 'BeverlyMacy' OR 'lauriemccabe' OR 'VanRijmenam' OR 'lisagualtieri' OR 'Joseph_Marks_' OR 'shawnrog' OR 'ellisbooker' OR 'rgkirkpatrick'\n",
        "\n",
        "\n",
        "'ValaAfshar' OR 'jenstirrup' OR 'marksmithvr' OR 'setlinger' OR 'mraad' OR 'vijayasankarv' OR 'John4man' OR 'NeilRaden' OR 'Dana_Gardner' OR 'maslett'\n",
        "\n",
        "\n",
        "'dvellante' OR 'tcrawford' OR 'nyike' OR 'mikeolson' OR 'Colinstrong' OR 'DTurnerBlogs' OR 'jburnmurdoch' OR 'TheGrok' OR 'TheSocialPitt' OR 'eric_kavanagh'\n",
        "\n",
        "\n",
        "'AliRebaie' OR 'louleporace' OR 'ITredux' OR 'jasonaverbook' OR 'BarryDevlin' OR 'shaunconnolly' OR 'RetailProphet' OR 'TonyCosentinoVR' OR 'lucadebiase' OR 'aregenberg'\n",
        "\n",
        "\n",
        "'LoraineLawson' OR 'prussom' OR 'Josh_Bersin' OR 'fhalper' OR 'BillRuh_GE' OR 'imbigdata' OR 'bobevansIT' OR 'lucatbarone' OR 'spangledrongo' OR 'InfoMgmtExec'\n",
        "\n",
        "\n",
        "'sinanaral' OR 'tamaradull' OR 'tweetsinha' OR 'EricDBrown' OR 'jfoley09' OR 'acroll' OR 'ColinJWhite' OR 'smoneill' OR 'juliebhunt' OR 'nicfish'\n",
        "\n",
        "\n",
        "'gkm1' OR 'williammcknight' OR 'jaimefitzgerald' OR 'craigmullins' OR 'brunoaziza' OR 'PaulDunay' OR 'BigDataSpeaker' OR 'WillmottPaul' OR 'johnlmyers44' OR 'tunvall'\n",
        "\n",
        "\n",
        "'rcalo' OR 'gleonhard' OR 'nancykoppdw' OR 'DavidLinthicum' OR 'jbdezard' OR 'bigdata' OR 'vmugonline' OR 'estebanmoro' OR 'FrankBuytendijk' OR 'BITechWatch'\n",
        "\n",
        "\n",
        "'davidfcarr' OR 'dr_morton' OR 'sandy_carter' OR 'DrBonnie360' OR 'simonlporter' OR 'Darryl_McDonald' OR 'jg21' OR 'Enderle' OR 'MandiBPro' OR 'pacoid'\n",
        "\n",
        "\n",
        "'HugoSarrazin' OR 'FindChrisTaylor' OR 'HealthcareWen' OR 'adsuara' OR 'christianve' OR 'hlsdk' OR 'SameerPatel' OR 'BradfordBrown' OR 'JamesMaguire' OR 'marcteerlink'\n",
        "\n",
        "\n",
        "'Hypatia_LeslieA' OR 'bevelson' OR 'ABridgwater' OR 'bkardon' OR 'PepeCerezo' OR 'tpowlas' OR 'petervan' OR 'MarkBonchek' OR 'slfisher' OR 'WyattKash'\n",
        "\n",
        "\n",
        "'David_MSullivan' OR 'rjwissin' OR 'datagenius' OR 'ronbodkin' OR 'Guille_Mas' OR 'digitalarun' OR 'sorayapa' OR 'DavidAmerland' OR 'etamb' OR 'applebyj'\n",
        "\n",
        "\n",
        "'ajbowles' OR 'rsallam' OR 'mphnyc' OR 'idin77' OR 'robinbloor' OR 'tinagroves' OR 'kimdossey' OR 'BobViolino' OR 'richardwinter' OR 'jahendler'\n",
        "\n",
        "\n",
        "'VishalTx' OR 'Marsee' OR 'Bilafer' OR 'StacyLeidwinger' OR 'mgershoff' OR 'TonyBaer' OR 'Charly_BG'\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "6"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}